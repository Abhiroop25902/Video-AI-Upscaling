{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Video AI Upscaling",
      "provenance": [],
      "authorship_tag": "ABX9TyM7NGTq0s7UAAytZLhNSpjg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b5f1446230e4a1e855547ceb78b9b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dd2537eb4c174c9aa386a92fa68e7227",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_46524330cc4c4fcf846a8730e1c5aa41",
              "IPY_MODEL_4253fd6f630e42c2b4db9c2928626803"
            ]
          }
        },
        "dd2537eb4c174c9aa386a92fa68e7227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46524330cc4c4fcf846a8730e1c5aa41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0859f9a501b5491f95d2c649c03d1230",
            "_dom_classes": [],
            "description": "Processing...: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 121,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 121,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_89cfd0e87436409d85dc9d4054391f33"
          }
        },
        "4253fd6f630e42c2b4db9c2928626803": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5869a5d794724fd2880929952d55ef99",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 121/121 [03:48&lt;00:00,  1.89s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4f49f8a330ef48faa269cfca53331145"
          }
        },
        "0859f9a501b5491f95d2c649c03d1230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "89cfd0e87436409d85dc9d4054391f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5869a5d794724fd2880929952d55ef99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4f49f8a330ef48faa269cfca53331145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Abhiroop25902/Video-AI-Upscaling/blob/main/Video_AI_Upscaling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql8vWBazqm4m"
      },
      "source": [
        "# Setup \n",
        "\n",
        "Just Run These Code Once to download and import all the pre-requsites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmv2rGyBq1wh"
      },
      "source": [
        "I have already built OpenCV from Source for GPU support, and the first line downloads it's python source code\n",
        "\n",
        "Second Line downloads the EDSR Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJcmV7Sp_Iz7",
        "outputId": "149a2e43-c09f-4b7c-839a-b0a59b9eebd7"
      },
      "source": [
        "!gdown --id 1--R75ERdRPjwh2XHWiRHno1FIuuA3iVg --output cv2.cpython-37m-x86_64-linux-gnu.so #enable GPU support\n",
        "!gdown --id 11wBtbU0smZKV2UG49e9RzyKkiIAYAXHn --output EDSR_x3.pb "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1--R75ERdRPjwh2XHWiRHno1FIuuA3iVg\n",
            "To: /content/cv2.cpython-37m-x86_64-linux-gnu.so\n",
            "1.01GB [00:05, 190MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=11wBtbU0smZKV2UG49e9RzyKkiIAYAXHn\n",
            "To: /content/EDSR_x3.pb\n",
            "38.5MB [00:00, 83.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOF0yXiZrOBU"
      },
      "source": [
        "Upgrading OpenCV and OpenCV contrib, Colab default doesn't have `dnn_superres` as of June 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftnjWmXsTvYO",
        "outputId": "f54d3cea-c294-4e04-b3a0-55e5f5ade350"
      },
      "source": [
        "!pip install --upgrade opencv-python\n",
        "!pip install --upgrade opencv-contrib-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/b3/3878691fec6babd78bbf4c71c720e1831cbb6ada61679613fe2fae080568/opencv_python-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (51.0MB)\n",
            "\u001b[K     |████████████████████████████████| 51.0MB 54kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: opencv-python\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed opencv-python-4.5.2.54\n",
            "Collecting opencv-contrib-python\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/f5/21227eb87cd5990a0f4235d8264db7d8f62f6a9ccbf2cd2c367f7d903cd2/opencv_contrib_python-4.5.2.54-cp37-cp37m-manylinux2014_x86_64.whl (57.4MB)\n",
            "\u001b[K     |████████████████████████████████| 57.4MB 53kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-contrib-python) (1.19.5)\n",
            "Installing collected packages: opencv-contrib-python\n",
            "  Found existing installation: opencv-contrib-python 4.1.2.30\n",
            "    Uninstalling opencv-contrib-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-contrib-python-4.1.2.30\n",
            "Successfully installed opencv-contrib-python-4.5.2.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiDm0Ngrrm45"
      },
      "source": [
        "Importing Required Stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGJl2P9S-IYB"
      },
      "source": [
        "import cv2 as cv\n",
        "from cv2 import dnn_superres\n",
        "from tqdm.notebook import tqdm #for google colab progressbar\n",
        "from time import time # for testing purposes"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtU8zs1Ir47Q"
      },
      "source": [
        "# Import Your Own Video"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk-9o_Aar8vR"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "You can directly drag and drop your video to the file explorer in the google colab, but I would not suggest it, primarily because Colab shows only a circular progress bar and no \"time remaining\" thing.\n",
        "\n",
        "Here's what I do:\n",
        "-\tUpload your video to google drive\n",
        "-   Make it's visibility to \"anyone with the link can view\"\n",
        "-   It's share link link will be something like \n",
        "    -   https ://drive.google.com/file/d/`<some key>`/view?usp=sharing\n",
        "-   Add command `!gdown --id <the key> --output <file name>` to any code snippet\n",
        "\n",
        "I have done this already for a sample `network.mp4` file \n",
        "\n",
        "NOTE: RAM Requirements are heavily dependant on original width and height of Video, the max resolution this was able to process in Colab Free was 640x360, anything more than that requires Colab Pro\n",
        "\n",
        "Additional Context: \n",
        "-   900 frames  640x360 video should take 37:44 min to process (2.95 sec/frame)\n",
        "-   120 frames  500x280 video should take 03:48 min to process (1.89 sec/frame)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9MSMqrZVAGP",
        "outputId": "dc839e4a-13ad-4a2b-d8a8-855e923060b9"
      },
      "source": [
        "# for network.mp4\n",
        "# https://drive.google.com/file/d/18oenWel4G3W2DXMZoKLrwZl3K5yUG__f/view?usp=sharing\n",
        "!gdown --id 18oenWel4G3W2DXMZoKLrwZl3K5yUG__f --output network.mp4\n",
        "\n",
        "# for earth.mp4\n",
        "# https://drive.google.com/file/d/1nrrDVyQBbBo9Gol8T-E-09bnhi4dJ4GS/view?usp=sharing\n",
        "# !gdown --id 1nrrDVyQBbBo9Gol8T-E-09bnhi4dJ4GS --output earth.mp4"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18oenWel4G3W2DXMZoKLrwZl3K5yUG__f\n",
            "To: /content/network.mp4\n",
            "\r  0% 0.00/169k [00:00<?, ?B/s]\r100% 169k/169k [00:00<00:00, 5.35MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOi9hZP52nYA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJpL_A5YugTP"
      },
      "source": [
        "put `path` as your `<file name>`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAU55MsG-d_i"
      },
      "source": [
        "path = \"network.mp4\"\n",
        "# path = \"earth.mp4\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GozMlVi9uoPB"
      },
      "source": [
        "# Inside Functions\n",
        "\n",
        "These two functions are main processing blocks "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-g_V2rvUAe"
      },
      "source": [
        "This function loop through the video once and returns fps, total_frames, width and height of the video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS-DszHAHlvo"
      },
      "source": [
        "def video_property(filepath):\n",
        "    \"return (fps, frames, width, height)\"\n",
        "\n",
        "    cap = cv.VideoCapture(filepath)\n",
        "\n",
        "    if (not cap.isOpened()):\n",
        "        raise ValueError('File Not Found: Check given path')\n",
        "\n",
        "    fps = cap.get(cv.CAP_PROP_FPS)\n",
        "    frames = 0\n",
        "    height = width = 0\n",
        "\n",
        "    while True:\n",
        "        ret, img = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        if(frames == 0):\n",
        "            height = img.shape[0]\n",
        "            width = img.shape[1]\n",
        "\n",
        "        frames = frames + 1\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    return fps, frames, width, height"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAGnCnY8vjX9"
      },
      "source": [
        "This is the main processing function, this imports the video and outputs 3 time upscaled video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-aPKZGOMv0"
      },
      "source": [
        "def generate_output_video(filepath):\n",
        "\n",
        "    #these parameters depends on video and should be changed\n",
        "    video_fps, video_total_frame, input_video_width, input_video_height = video_property(filepath)\n",
        "\n",
        "    #multiplied by 3 as we are incresing output size by a factor of 3\n",
        "    output_video_width = 3*input_video_width \n",
        "    output_video_height = 3*input_video_height\n",
        "\n",
        "    cap = cv.VideoCapture(filepath)\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv.VideoWriter('output.mp4',fourcc, video_fps,(output_video_width,output_video_height))\n",
        "\n",
        "    \n",
        "    # Create an Super-Res object\n",
        "    sr = dnn_superres.DnnSuperResImpl_create()\n",
        "\n",
        "    # Read the desired model\n",
        "    sr.readModel(\"EDSR_x3.pb\")\n",
        "    \n",
        "    # Set the desired model and scale to get correct pre- and post-processing\n",
        "    sr.setModel(\"edsr\", 3)\n",
        "\n",
        "    #setting dnn to use CUDA\n",
        "    sr.setPreferableBackend(cv.dnn.DNN_BACKEND_CUDA)\n",
        "    sr.setPreferableTarget(cv.dnn.DNN_TARGET_CUDA)\n",
        "\n",
        "    # initial_time=time()\n",
        "    for i in tqdm (range (video_total_frame), desc=\"Processing...\"):    \n",
        "        # Read image\n",
        "        ret,image = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Upscale the image\n",
        "        result = sr.upsample(image)\n",
        "\n",
        "        out.write(result)\n",
        "\n",
        "\n",
        "    #release capture and output videos\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    print(\"Processing Completed, Download 'output.mp4' to View Results\")\n",
        "    # print(f\"Time taken to process the input: {time()-initial_time} seconds\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnnf50BPutiY"
      },
      "source": [
        "# Main Executing Code\n",
        "\n",
        "This will generate `output.mp4` upscaled to 3 times height and width of original video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "0b5f1446230e4a1e855547ceb78b9b9c",
            "dd2537eb4c174c9aa386a92fa68e7227",
            "46524330cc4c4fcf846a8730e1c5aa41",
            "4253fd6f630e42c2b4db9c2928626803",
            "0859f9a501b5491f95d2c649c03d1230",
            "89cfd0e87436409d85dc9d4054391f33",
            "5869a5d794724fd2880929952d55ef99",
            "4f49f8a330ef48faa269cfca53331145"
          ]
        },
        "id": "nf_lwGA1M76O",
        "outputId": "5bdb594b-91c7-4340-9dba-ebc7c687834c"
      },
      "source": [
        "generate_output_video(path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b5f1446230e4a1e855547ceb78b9b9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Processing...', max=121.0, style=ProgressStyle(descriptio…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing Completed, Download 'output.mp4' to View Results\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}